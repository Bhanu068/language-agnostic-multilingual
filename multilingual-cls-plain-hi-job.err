Using custom data configuration default-language=hi
Reusing dataset xnli (/home/bhanuv/.cache/huggingface/datasets/xnli/default-language=hi/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
Some weights of the model checkpoint at facebook/m2m100_418M were not used when initializing M2M100Encoder: ['model.encoder.layers.8.fc2.weight', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.6.fc2.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.11.fc1.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.fc1.weight', 'model.decoder.layers.1.fc2.bias', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.6.fc1.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.10.fc2.weight', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.0.fc2.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layers.11.fc1.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.fc2.bias', 'model.encoder.layers.1.fc2.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layer_norm.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.fc1.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.encoder.layers.8.fc1.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.3.fc2.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.shared.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.encoder.layers.1.fc1.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc2.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.3.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.7.fc2.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layer_norm.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.2.fc2.weight', 'model.encoder.layer_norm.weight', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layer_norm.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.5.fc1.bias', 'model.encoder.layers.9.fc2.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.encoder.embed_tokens.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'lm_head.weight', 'model.decoder.layers.3.fc2.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.fc1.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.1.final_layer_norm.weight']
- This IS expected if you are initializing M2M100Encoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing M2M100Encoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of M2M100Encoder were not initialized from the model checkpoint at facebook/m2m100_418M and are newly initialized: ['model.layers.11.self_attn.v_proj.weight', 'model.layers.3.fc2.weight', 'model.layers.2.fc1.weight', 'model.layers.2.self_attn_layer_norm.bias', 'model.layers.3.self_attn.out_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.fc1.bias', 'model.layers.1.self_attn.out_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn_layer_norm.weight', 'model.layers.4.self_attn.out_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn_layer_norm.weight', 'model.layers.10.fc1.bias', 'model.layers.10.fc2.weight', 'model.layer_norm.weight', 'model.layers.5.fc1.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.10.fc2.bias', 'model.layers.9.final_layer_norm.weight', 'model.layers.8.self_attn_layer_norm.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.4.fc1.weight', 'model.layers.2.self_attn.out_proj.weight', 'model.layers.11.fc2.bias', 'model.layers.10.self_attn.out_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.0.self_attn.out_proj.bias', 'model.layers.6.final_layer_norm.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.5.self_attn_layer_norm.weight', 'model.layers.4.self_attn.out_proj.bias', 'model.layers.8.self_attn.out_proj.weight', 'model.layers.7.self_attn.out_proj.weight', 'model.layers.8.self_attn_layer_norm.weight', 'model.layers.3.fc1.weight', 'model.layers.3.fc1.bias', 'model.layers.6.fc2.bias', 'model.layers.10.final_layer_norm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.5.final_layer_norm.weight', 'model.layers.1.final_layer_norm.weight', 'model.layers.6.self_attn.out_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.9.self_attn.out_proj.weight', 'model.layers.8.fc1.bias', 'model.layers.0.fc1.weight', 'model.layers.11.self_attn.out_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.8.self_attn.out_proj.bias', 'model.layers.8.fc2.bias', 'model.layers.5.final_layer_norm.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.4.final_layer_norm.weight', 'model.layers.11.final_layer_norm.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.1.self_attn.out_proj.weight', 'model.layers.3.self_attn.out_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.7.fc1.bias', 'model.embed_positions.weights', 'model.layers.2.final_layer_norm.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.6.self_attn_layer_norm.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.1.self_attn_layer_norm.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.5.self_attn_layer_norm.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.4.self_attn_layer_norm.weight', 'model.layers.7.fc1.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.11.self_attn.out_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.3.self_attn_layer_norm.bias', 'model.layers.4.fc1.bias', 'model.layers.6.fc1.weight', 'model.layers.0.fc1.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.4.final_layer_norm.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.3.final_layer_norm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.8.final_layer_norm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.out_proj.bias', 'model.layers.6.self_attn_layer_norm.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.11.self_attn_layer_norm.bias', 'model.layers.3.self_attn_layer_norm.weight', 'model.layers.6.self_attn.out_proj.weight', 'model.layers.7.self_attn.out_proj.bias', 'model.layers.9.fc2.weight', 'model.layers.10.self_attn.out_proj.weight', 'model.layers.0.final_layer_norm.weight', 'model.layers.3.final_layer_norm.weight', 'model.layers.9.final_layer_norm.bias', 'model.layers.1.fc1.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.embed_tokens.weight', 'model.layers.0.fc2.weight', 'model.layers.1.fc2.bias', 'model.layers.8.final_layer_norm.weight', 'model.layers.9.self_attn.out_proj.bias', 'model.layers.7.final_layer_norm.weight', 'model.layers.10.fc1.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.11.self_attn_layer_norm.weight', 'model.layers.1.fc1.weight', 'model.layers.9.fc2.bias', 'model.layers.11.final_layer_norm.weight', 'model.layers.10.self_attn_layer_norm.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.fc2.weight', 'model.layers.3.fc2.bias', 'model.layers.1.self_attn_layer_norm.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn_layer_norm.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.7.fc2.bias', 'model.layers.5.fc2.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.4.fc2.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.8.fc1.weight', 'model.layers.5.fc2.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.final_layer_norm.weight', 'model.layers.7.fc2.weight', 'model.layers.9.self_attn_layer_norm.bias', 'model.layers.8.fc2.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.11.fc2.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.0.self_attn_layer_norm.bias', 'model.layers.2.self_attn_layer_norm.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.2.fc1.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.5.self_attn.out_proj.bias', 'model.layers.11.fc1.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.final_layer_norm.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.9.self_attn_layer_norm.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.6.final_layer_norm.weight', 'model.layers.9.fc1.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.5.self_attn.out_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.7.final_layer_norm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.9.fc1.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.10.final_layer_norm.weight', 'model.layers.6.fc2.weight', 'model.layers.4.fc2.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.2.fc2.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.7.self_attn_layer_norm.bias', 'model.layers.0.fc2.bias', 'model.layers.2.fc2.bias', 'model.layer_norm.bias', 'model.layers.5.fc1.weight', 'model.layers.11.fc1.weight', 'model.layers.0.self_attn_layer_norm.weight', 'model.layers.0.self_attn.out_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.0.final_layer_norm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /home/bhanuv/.cache/huggingface/datasets/xnli/default-language=hi/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd/cache-ad082a5689c9d0d8.arrow
Using amp half precision backend
The following columns in the test set  don't have a corresponding argument in `M2M100.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `M2M100.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 5010
  Batch size = 128
  0%|          | 0/40 [00:00<?, ?it/s]  8%|▊         | 3/40 [00:00<00:01, 27.81it/s] 15%|█▌        | 6/40 [00:00<00:01, 20.64it/s] 22%|██▎       | 9/40 [00:00<00:01, 18.75it/s] 28%|██▊       | 11/40 [00:00<00:01, 17.79it/s] 32%|███▎      | 13/40 [00:00<00:01, 16.28it/s] 38%|███▊      | 15/40 [00:00<00:01, 16.73it/s] 42%|████▎     | 17/40 [00:00<00:01, 16.87it/s] 50%|█████     | 20/40 [00:01<00:01, 17.93it/s] 55%|█████▌    | 22/40 [00:01<00:01, 17.43it/s] 60%|██████    | 24/40 [00:01<00:00, 16.46it/s] 65%|██████▌   | 26/40 [00:01<00:00, 16.17it/s] 70%|███████   | 28/40 [00:01<00:00, 16.03it/s] 75%|███████▌  | 30/40 [00:01<00:00, 16.40it/s] 80%|████████  | 32/40 [00:01<00:00, 15.89it/s] 85%|████████▌ | 34/40 [00:02<00:00, 15.52it/s] 90%|█████████ | 36/40 [00:02<00:00, 14.37it/s] 95%|█████████▌| 38/40 [00:02<00:00, 14.17it/s]100%|██████████| 40/40 [00:02<00:00, 15.66it/s]