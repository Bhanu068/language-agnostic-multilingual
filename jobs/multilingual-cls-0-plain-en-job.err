Using custom data configuration default-language=en
Reusing dataset xnli (/home/bhanuv/.cache/huggingface/datasets/xnli/default-language=en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
Some weights of the model checkpoint at facebook/m2m100_418M were not used when initializing M2M100Encoder: ['model.decoder.layers.3.fc2.weight', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'lm_head.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layer_norm.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.encoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc2.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.1.fc1.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.9.fc1.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.9.fc2.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.10.fc1.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.encoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layer_norm.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.embed_tokens.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.9.fc2.weight', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc2.weight', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.embed_tokens.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.8.fc2.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.4.fc2.bias', 'model.encoder.layers.5.fc2.weight', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.2.fc2.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.0.fc1.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.0.fc1.weight', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.7.fc2.weight', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.shared.weight', 'model.encoder.layers.5.fc1.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.7.fc2.weight', 'model.encoder.layers.3.fc1.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.0.fc1.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.4.fc1.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.6.fc1.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.fc2.bias', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.8.fc2.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.10.fc2.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.fc2.weight', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.3.fc1.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.encoder.layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.encoder.layers.1.fc2.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.6.fc2.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.1.fc1.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.encoder.layers.6.fc2.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.0.fc2.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.9.fc1.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layer_norm.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.8.fc2.weight', 'model.encoder.layers.1.fc2.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.8.fc1.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.fc1.bias']
- This IS expected if you are initializing M2M100Encoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing M2M100Encoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of M2M100Encoder were not initialized from the model checkpoint at facebook/m2m100_418M and are newly initialized: ['model.layers.8.self_attn_layer_norm.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.8.self_attn_layer_norm.weight', 'model.layers.5.fc2.weight', 'model.layers.11.fc2.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.5.self_attn_layer_norm.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.0.self_attn_layer_norm.weight', 'model.layers.10.fc1.bias', 'model.layers.4.self_attn.out_proj.bias', 'model.layers.7.fc1.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.5.self_attn.out_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.2.self_attn.out_proj.weight', 'model.layers.8.final_layer_norm.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.9.self_attn.out_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.9.fc2.weight', 'model.layers.2.fc1.bias', 'model.layers.2.final_layer_norm.weight', 'model.layers.11.self_attn_layer_norm.weight', 'model.layers.2.self_attn_layer_norm.bias', 'model.layers.10.self_attn.out_proj.bias', 'model.layers.11.self_attn.out_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.0.final_layer_norm.weight', 'model.layers.6.self_attn.out_proj.bias', 'model.layers.3.fc2.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.fc1.weight', 'model.layers.7.fc2.weight', 'model.layers.4.self_attn_layer_norm.bias', 'model.layers.7.self_attn.out_proj.weight', 'model.layers.0.self_attn.out_proj.weight', 'model.layers.7.fc1.weight', 'model.layers.4.final_layer_norm.weight', 'model.layers.10.self_attn_layer_norm.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.4.fc1.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.1.fc1.weight', 'model.layers.0.final_layer_norm.bias', 'model.layers.4.self_attn.out_proj.weight', 'model.layers.2.fc2.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.out_proj.bias', 'model.layers.8.final_layer_norm.bias', 'model.layers.5.fc2.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.5.final_layer_norm.bias', 'model.layers.8.fc2.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.5.final_layer_norm.weight', 'model.layers.4.self_attn_layer_norm.weight', 'model.layers.4.fc1.weight', 'model.layers.1.self_attn.out_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.10.final_layer_norm.weight', 'model.layers.0.fc2.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.out_proj.bias', 'model.layers.6.self_attn_layer_norm.bias', 'model.layers.0.fc1.weight', 'model.layers.5.self_attn_layer_norm.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.9.fc1.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.7.final_layer_norm.bias', 'model.layers.6.fc2.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.9.self_attn.out_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.11.final_layer_norm.bias', 'model.layers.3.self_attn.out_proj.bias', 'model.layers.4.fc2.bias', 'model.layers.0.self_attn.out_proj.bias', 'model.layers.1.fc1.bias', 'model.layer_norm.weight', 'model.layers.3.self_attn_layer_norm.weight', 'model.layers.10.self_attn.out_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.0.fc1.bias', 'model.layers.2.fc2.bias', 'model.layers.3.self_attn_layer_norm.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.fc2.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.7.final_layer_norm.weight', 'model.layers.3.self_attn.out_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.0.fc2.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.final_layer_norm.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layer_norm.bias', 'model.layers.11.final_layer_norm.weight', 'model.layers.2.final_layer_norm.bias', 'model.layers.10.fc2.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.7.self_attn_layer_norm.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.final_layer_norm.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.9.final_layer_norm.weight', 'model.layers.5.self_attn.out_proj.bias', 'model.layers.3.fc1.bias', 'model.layers.8.fc1.weight', 'model.layers.9.final_layer_norm.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.11.self_attn.out_proj.bias', 'model.layers.7.fc2.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.8.fc2.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.3.fc1.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.10.final_layer_norm.bias', 'model.layers.6.final_layer_norm.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.1.self_attn_layer_norm.bias', 'model.layers.3.final_layer_norm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.8.self_attn.out_proj.weight', 'model.layers.8.self_attn.out_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.1.final_layer_norm.bias', 'model.layers.11.fc1.weight', 'model.layers.10.fc2.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.9.fc2.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.2.self_attn_layer_norm.weight', 'model.layers.6.self_attn.out_proj.weight', 'model.layers.6.final_layer_norm.bias', 'model.layers.11.fc1.bias', 'model.layers.11.self_attn_layer_norm.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.10.self_attn_layer_norm.bias', 'model.layers.6.fc1.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.4.final_layer_norm.bias', 'model.layers.10.fc1.weight', 'model.layers.1.fc2.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.8.fc1.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.1.self_attn.out_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.2.fc1.weight', 'model.layers.4.fc2.weight', 'model.embed_positions.weights', 'model.layers.6.fc1.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.embed_tokens.weight', 'model.layers.9.fc1.bias', 'model.layers.9.self_attn_layer_norm.bias', 'model.layers.3.fc2.weight', 'model.layers.0.self_attn_layer_norm.bias', 'model.layers.7.self_attn_layer_norm.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.1.fc2.weight', 'model.layers.5.fc1.bias', 'model.layers.11.fc2.bias', 'model.layers.6.self_attn_layer_norm.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.9.self_attn_layer_norm.weight', 'model.layers.1.self_attn_layer_norm.weight', 'model.layers.3.self_attn.v_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /home/bhanuv/.cache/huggingface/datasets/xnli/default-language=en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd/cache-e13ef5ddab5d6db1.arrow
Using amp half precision backend
The following columns in the test set  don't have a corresponding argument in `M2M100.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `M2M100.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 5010
  Batch size = 128
  0%|          | 0/40 [00:00<?, ?it/s] 10%|█         | 4/40 [00:00<00:01, 32.84it/s] 20%|██        | 8/40 [00:00<00:01, 25.66it/s] 28%|██▊       | 11/40 [00:00<00:01, 23.40it/s] 35%|███▌      | 14/40 [00:00<00:01, 22.29it/s] 42%|████▎     | 17/40 [00:00<00:01, 21.78it/s] 50%|█████     | 20/40 [00:00<00:00, 22.33it/s] 57%|█████▊    | 23/40 [00:01<00:00, 21.43it/s] 65%|██████▌   | 26/40 [00:01<00:00, 21.44it/s] 72%|███████▎  | 29/40 [00:01<00:00, 21.18it/s] 80%|████████  | 32/40 [00:01<00:00, 20.57it/s] 88%|████████▊ | 35/40 [00:01<00:00, 19.62it/s] 92%|█████████▎| 37/40 [00:01<00:00, 18.35it/s] 98%|█████████▊| 39/40 [00:01<00:00, 18.34it/s]100%|██████████| 40/40 [00:02<00:00, 19.55it/s]