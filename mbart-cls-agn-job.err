Using custom data configuration default-language=en
Reusing dataset xnli (/home/bhanuv/.cache/huggingface/datasets/xnli/default-language=en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
Some weights of the model checkpoint at facebook/mbart-large-50-many-to-many-mmt were not used when initializing MBartModel: ['lm_head.weight', 'final_logits_bias']
- This IS expected if you are initializing MBartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MBartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
  0%|          | 0/3 [00:00<?, ?ba/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 33%|███▎      | 1/3 [00:00<00:00,  2.61ba/s] 67%|██████▋   | 2/3 [00:00<00:00,  4.27ba/s]100%|██████████| 3/3 [00:00<00:00,  5.15ba/s]
Using amp half precision backend
The following columns in the training set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running training *****
  Num examples = 2490
  Num Epochs = 80
  Instantaneous batch size per device = 128
  Total train batch size (w. parallel, distributed & accumulation) = 128
  Gradient Accumulation steps = 1
  Total optimization steps = 1600
  0%|          | 0/1600 [00:00<?, ?it/s]  0%|          | 1/1600 [00:00<10:01,  2.66it/s]  0%|          | 4/1600 [00:00<02:56,  9.07it/s]  0%|          | 7/1600 [00:00<02:01, 13.06it/s]  1%|          | 10/1600 [00:00<01:38, 16.09it/s]  1%|          | 13/1600 [00:00<01:27, 18.10it/s]  1%|          | 16/1600 [00:01<01:22, 19.32it/s]  1%|          | 19/1600 [00:01<01:17, 20.40it/s]                                                   1%|▏         | 20/1600 [00:01<01:17, 20.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.79it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.53it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.05it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.51it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                 
                                               [A  1%|▏         | 20/1600 [00:02<01:17, 20.40it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-20
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-20/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-20/special_tokens_map.json
  1%|▏         | 22/1600 [00:09<25:03,  1.05it/s]  2%|▏         | 25/1600 [00:09<17:29,  1.50it/s]  2%|▏         | 28/1600 [00:09<12:23,  2.11it/s]  2%|▏         | 31/1600 [00:10<08:55,  2.93it/s]  2%|▏         | 34/1600 [00:10<06:31,  4.00it/s]  2%|▏         | 37/1600 [00:10<04:54,  5.31it/s]  2%|▎         | 40/1600 [00:10<03:42,  7.02it/s]                                                   2%|▎         | 40/1600 [00:10<03:42,  7.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.55it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.43it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.96it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.36it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.10it/s][A                                                 
                                               [A  2%|▎         | 40/1600 [00:11<03:42,  7.02it/s]
100%|██████████| 20/20 [00:00<00:00, 27.10it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-40
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-40/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-40/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-20] due to args.save_total_limit
  3%|▎         | 43/1600 [00:19<25:46,  1.01it/s]  3%|▎         | 45/1600 [00:19<20:17,  1.28it/s]  3%|▎         | 48/1600 [00:19<14:03,  1.84it/s]  3%|▎         | 51/1600 [00:19<09:58,  2.59it/s]  3%|▎         | 54/1600 [00:19<07:11,  3.58it/s]  4%|▎         | 57/1600 [00:20<05:18,  4.84it/s]  4%|▍         | 60/1600 [00:20<03:58,  6.44it/s]                                                   4%|▍         | 60/1600 [00:20<03:58,  6.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.28it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.27it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.81it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.35it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.07it/s][A                                                 
                                               [A  4%|▍         | 60/1600 [00:21<03:58,  6.44it/s]
100%|██████████| 20/20 [00:00<00:00, 27.07it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-60
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-60/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-60/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-40] due to args.save_total_limit
  4%|▍         | 63/1600 [00:29<25:55,  1.01s/it]  4%|▍         | 66/1600 [00:29<18:24,  1.39it/s]  4%|▍         | 69/1600 [00:29<13:10,  1.94it/s]  4%|▍         | 72/1600 [00:29<09:32,  2.67it/s]  5%|▍         | 75/1600 [00:29<07:00,  3.63it/s]  5%|▍         | 78/1600 [00:29<05:12,  4.87it/s]                                                   5%|▌         | 80/1600 [00:29<05:12,  4.87it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.27it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.27it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.88it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.35it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.14it/s][A                                                 
                                               [A  5%|▌         | 80/1600 [00:30<05:12,  4.87it/s]
100%|██████████| 20/20 [00:00<00:00, 27.14it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-80
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-80/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-80/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-60] due to args.save_total_limit
  5%|▌         | 81/1600 [00:38<25:59,  1.03s/it]  5%|▌         | 83/1600 [00:38<20:28,  1.24it/s]  5%|▌         | 85/1600 [00:38<15:49,  1.60it/s]  6%|▌         | 88/1600 [00:38<10:47,  2.33it/s]  6%|▌         | 91/1600 [00:39<07:37,  3.30it/s]  6%|▌         | 94/1600 [00:39<05:32,  4.53it/s]  6%|▌         | 97/1600 [00:39<04:07,  6.07it/s]  6%|▋         | 100/1600 [00:39<03:09,  7.93it/s]                                                    6%|▋         | 100/1600 [00:39<03:09,  7.93it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.69it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.42it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.01it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.56it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                  
                                               [A  6%|▋         | 100/1600 [00:40<03:09,  7.93it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-100
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-100/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-100/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-80] due to args.save_total_limit
  6%|▋         | 103/1600 [00:48<24:59,  1.00s/it]  7%|▋         | 106/1600 [00:48<17:40,  1.41it/s]  7%|▋         | 109/1600 [00:48<12:37,  1.97it/s]  7%|▋         | 112/1600 [00:48<09:06,  2.72it/s]  7%|▋         | 115/1600 [00:48<06:41,  3.70it/s]  7%|▋         | 118/1600 [00:49<04:58,  4.96it/s]                                                    8%|▊         | 120/1600 [00:49<04:58,  4.96it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.50it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.22it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.78it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.24it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.06it/s][A                                                  
                                               [A  8%|▊         | 120/1600 [00:50<04:58,  4.96it/s]
100%|██████████| 20/20 [00:00<00:00, 27.06it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-120
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-120/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-120/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-100] due to args.save_total_limit
  8%|▊         | 121/1600 [00:57<25:36,  1.04s/it]  8%|▊         | 123/1600 [00:58<20:09,  1.22it/s]  8%|▊         | 126/1600 [00:58<13:59,  1.76it/s]  8%|▊         | 129/1600 [00:58<09:54,  2.48it/s]  8%|▊         | 132/1600 [00:58<07:08,  3.42it/s]  8%|▊         | 135/1600 [00:58<05:16,  4.62it/s]  9%|▊         | 138/1600 [00:58<03:58,  6.13it/s]                                                    9%|▉         | 140/1600 [00:58<03:58,  6.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.41it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.31it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.55it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.20it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.08it/s][A                                                  
                                               [A  9%|▉         | 140/1600 [00:59<03:58,  6.13it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-140
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-140/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-140/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-120] due to args.save_total_limit
  9%|▉         | 141/1600 [01:07<25:04,  1.03s/it]  9%|▉         | 143/1600 [01:07<19:43,  1.23it/s]  9%|▉         | 145/1600 [01:08<15:13,  1.59it/s]  9%|▉         | 148/1600 [01:08<10:21,  2.34it/s]  9%|▉         | 151/1600 [01:08<07:17,  3.31it/s] 10%|▉         | 154/1600 [01:08<05:17,  4.55it/s] 10%|▉         | 157/1600 [01:08<03:58,  6.06it/s] 10%|█         | 160/1600 [01:08<03:01,  7.93it/s]                                                   10%|█         | 160/1600 [01:08<03:01,  7.93it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.44it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.34it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.91it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.49it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.27it/s][A                                                  
                                               [A 10%|█         | 160/1600 [01:09<03:01,  7.93it/s]
100%|██████████| 20/20 [00:00<00:00, 27.27it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-160
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-160/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-160/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-140] due to args.save_total_limit
 10%|█         | 163/1600 [01:17<24:38,  1.03s/it] 10%|█         | 166/1600 [01:18<17:27,  1.37it/s] 11%|█         | 169/1600 [01:18<12:27,  1.91it/s] 11%|█         | 172/1600 [01:18<09:00,  2.64it/s] 11%|█         | 175/1600 [01:18<06:35,  3.60it/s] 11%|█         | 178/1600 [01:18<04:54,  4.83it/s]                                                   11%|█▏        | 180/1600 [01:18<04:54,  4.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 35.79it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.13it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.54it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.38it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.19it/s][A                                                  
                                               [A 11%|█▏        | 180/1600 [01:19<04:54,  4.83it/s]
100%|██████████| 20/20 [00:00<00:00, 27.19it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-180
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-180/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-180/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-160] due to args.save_total_limit
 11%|█▏        | 181/1600 [01:27<24:56,  1.05s/it] 11%|█▏        | 183/1600 [01:27<19:37,  1.20it/s] 12%|█▏        | 186/1600 [01:27<13:35,  1.73it/s] 12%|█▏        | 189/1600 [01:28<09:35,  2.45it/s] 12%|█▏        | 192/1600 [01:28<06:55,  3.38it/s] 12%|█▏        | 195/1600 [01:28<05:06,  4.58it/s] 12%|█▏        | 198/1600 [01:28<03:51,  6.06it/s]                                                   12%|█▎        | 200/1600 [01:28<03:51,  6.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.43it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.32it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.33it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.12it/s][A                                                  
                                               [A 12%|█▎        | 200/1600 [01:29<03:51,  6.06it/s]
100%|██████████| 20/20 [00:00<00:00, 27.12it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-200
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-200/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-200/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-180] due to args.save_total_limit
 13%|█▎        | 201/1600 [01:37<23:59,  1.03s/it] 13%|█▎        | 203/1600 [01:37<18:50,  1.24it/s] 13%|█▎        | 206/1600 [01:37<13:03,  1.78it/s] 13%|█▎        | 209/1600 [01:37<09:15,  2.50it/s] 13%|█▎        | 212/1600 [01:37<06:40,  3.46it/s] 13%|█▎        | 215/1600 [01:38<04:56,  4.67it/s] 14%|█▎        | 218/1600 [01:38<03:44,  6.15it/s]                                                   14%|█▍        | 220/1600 [01:38<03:44,  6.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.74it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.57it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.14it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.61it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                  
                                               [A 14%|█▍        | 220/1600 [01:39<03:44,  6.15it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-220
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-220/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-220/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-200] due to args.save_total_limit
 14%|█▍        | 221/1600 [01:47<23:24,  1.02s/it] 14%|█▍        | 223/1600 [01:47<18:23,  1.25it/s] 14%|█▍        | 225/1600 [01:47<14:11,  1.62it/s] 14%|█▍        | 228/1600 [01:47<09:39,  2.37it/s] 14%|█▍        | 231/1600 [01:47<06:48,  3.35it/s] 15%|█▍        | 234/1600 [01:47<04:56,  4.61it/s] 15%|█▍        | 237/1600 [01:47<03:41,  6.15it/s] 15%|█▌        | 240/1600 [01:48<02:48,  8.06it/s]                                                   15%|█▌        | 240/1600 [01:48<02:48,  8.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.54it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.31it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.79it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.13it/s][A                                                  
                                               [A 15%|█▌        | 240/1600 [01:48<02:48,  8.06it/s]
100%|██████████| 20/20 [00:00<00:00, 27.13it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-240
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-240/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-240/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-220] due to args.save_total_limit
 15%|█▌        | 243/1600 [01:56<22:33,  1.00it/s] 15%|█▌        | 246/1600 [01:57<15:58,  1.41it/s] 16%|█▌        | 249/1600 [01:57<11:25,  1.97it/s] 16%|█▌        | 252/1600 [01:57<08:15,  2.72it/s] 16%|█▌        | 255/1600 [01:57<06:04,  3.69it/s] 16%|█▌        | 258/1600 [01:57<04:32,  4.93it/s]                                                   16%|█▋        | 260/1600 [01:57<04:31,  4.93it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 35.84it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.96it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.58it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.50it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.32it/s][A                                                  
                                               [A 16%|█▋        | 260/1600 [01:58<04:31,  4.93it/s]
100%|██████████| 20/20 [00:00<00:00, 27.32it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-260
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-260/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-260/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-240] due to args.save_total_limit
 16%|█▋        | 261/1600 [02:06<23:27,  1.05s/it] 16%|█▋        | 263/1600 [02:06<18:27,  1.21it/s] 17%|█▋        | 265/1600 [02:06<14:15,  1.56it/s] 17%|█▋        | 268/1600 [02:07<09:43,  2.28it/s] 17%|█▋        | 271/1600 [02:07<06:50,  3.24it/s] 17%|█▋        | 274/1600 [02:07<04:58,  4.44it/s] 17%|█▋        | 277/1600 [02:07<03:43,  5.93it/s] 18%|█▊        | 280/1600 [02:07<02:47,  7.86it/s]                                                   18%|█▊        | 280/1600 [02:07<02:47,  7.86it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.44it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.29it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.85it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.42it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                  
                                               [A 18%|█▊        | 280/1600 [02:08<02:47,  7.86it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-280
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-280/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-280/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-260] due to args.save_total_limit
 18%|█▊        | 283/1600 [02:16<22:08,  1.01s/it] 18%|█▊        | 286/1600 [02:16<15:42,  1.39it/s] 18%|█▊        | 288/1600 [02:16<12:24,  1.76it/s] 18%|█▊        | 291/1600 [02:16<08:39,  2.52it/s] 18%|█▊        | 294/1600 [02:17<06:13,  3.50it/s] 19%|█▊        | 297/1600 [02:17<04:34,  4.75it/s] 19%|█▉        | 300/1600 [02:17<03:25,  6.34it/s]                                                   19%|█▉        | 300/1600 [02:17<03:25,  6.34it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.69it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.51it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.96it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.48it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.29it/s][A                                                  
                                               [A 19%|█▉        | 300/1600 [02:18<03:25,  6.34it/s]
100%|██████████| 20/20 [00:00<00:00, 27.29it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-300
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-300/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-300/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-280] due to args.save_total_limit
 19%|█▉        | 303/1600 [02:26<23:25,  1.08s/it] 19%|█▉        | 306/1600 [02:27<16:34,  1.30it/s] 19%|█▉        | 309/1600 [02:27<11:50,  1.82it/s] 20%|█▉        | 312/1600 [02:27<08:32,  2.51it/s] 20%|█▉        | 315/1600 [02:27<06:14,  3.43it/s] 20%|█▉        | 318/1600 [02:27<04:41,  4.55it/s]                                                   20%|██        | 320/1600 [02:27<04:41,  4.55it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 35.36it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.90it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.42it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.23it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.11it/s][A                                                  
                                               [A 20%|██        | 320/1600 [02:28<04:41,  4.55it/s]
100%|██████████| 20/20 [00:00<00:00, 27.11it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-320
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-320/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-320/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-300] due to args.save_total_limit
 20%|██        | 321/1600 [02:37<24:09,  1.13s/it] 20%|██        | 323/1600 [02:37<19:00,  1.12it/s] 20%|██        | 325/1600 [02:37<14:39,  1.45it/s] 20%|██        | 328/1600 [02:37<09:58,  2.13it/s] 21%|██        | 331/1600 [02:37<07:00,  3.02it/s] 21%|██        | 334/1600 [02:38<05:03,  4.17it/s] 21%|██        | 337/1600 [02:38<03:45,  5.61it/s] 21%|██▏       | 340/1600 [02:38<02:50,  7.40it/s]                                                   21%|██▏       | 340/1600 [02:38<02:50,  7.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.61it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.37it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.87it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.39it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.13it/s][A                                                  
                                               [A 21%|██▏       | 340/1600 [02:39<02:50,  7.40it/s]
100%|██████████| 20/20 [00:00<00:00, 27.13it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-340
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-340/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-340/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-320] due to args.save_total_limit
 21%|██▏       | 343/1600 [02:47<21:58,  1.05s/it] 22%|██▏       | 346/1600 [02:47<15:33,  1.34it/s] 22%|██▏       | 349/1600 [02:47<11:06,  1.88it/s] 22%|██▏       | 352/1600 [02:48<08:00,  2.60it/s] 22%|██▏       | 355/1600 [02:48<05:50,  3.55it/s] 22%|██▏       | 358/1600 [02:48<04:21,  4.76it/s]                                                   22%|██▎       | 360/1600 [02:48<04:20,  4.76it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.45it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.34it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.85it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.32it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.11it/s][A                                                  
                                               [A 22%|██▎       | 360/1600 [02:49<04:20,  4.76it/s]
100%|██████████| 20/20 [00:00<00:00, 27.11it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-360
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-360/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-360/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-340] due to args.save_total_limit
 23%|██▎       | 361/1600 [02:58<23:41,  1.15s/it] 23%|██▎       | 363/1600 [02:58<18:38,  1.11it/s] 23%|██▎       | 365/1600 [02:58<14:22,  1.43it/s] 23%|██▎       | 368/1600 [02:58<09:46,  2.10it/s] 23%|██▎       | 370/1600 [02:58<07:37,  2.69it/s] 23%|██▎       | 373/1600 [02:58<05:18,  3.85it/s] 24%|██▎       | 376/1600 [02:58<03:51,  5.29it/s] 24%|██▎       | 379/1600 [02:59<02:55,  6.96it/s]                                                   24%|██▍       | 380/1600 [02:59<02:55,  6.96it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.04it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.93it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.54it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.46it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.27it/s][A                                                  
                                               [A 24%|██▍       | 380/1600 [03:00<02:55,  6.96it/s]
100%|██████████| 20/20 [00:00<00:00, 27.27it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-380
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-380/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-380/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-360] due to args.save_total_limit
 24%|██▍       | 382/1600 [03:08<21:46,  1.07s/it] 24%|██▍       | 384/1600 [03:08<16:58,  1.19it/s] 24%|██▍       | 387/1600 [03:08<11:38,  1.74it/s] 24%|██▍       | 390/1600 [03:08<08:11,  2.46it/s] 25%|██▍       | 393/1600 [03:08<05:52,  3.42it/s] 25%|██▍       | 396/1600 [03:09<04:19,  4.64it/s] 25%|██▍       | 399/1600 [03:09<03:15,  6.13it/s]                                                   25%|██▌       | 400/1600 [03:09<03:15,  6.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.65it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.45it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.04it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.53it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.28it/s][A                                                  
                                               [A 25%|██▌       | 400/1600 [03:10<03:15,  6.13it/s]
100%|██████████| 20/20 [00:00<00:00, 27.28it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-400
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-400/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-400/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-380] due to args.save_total_limit
 25%|██▌       | 402/1600 [03:18<20:18,  1.02s/it] 25%|██▌       | 405/1600 [03:18<14:23,  1.38it/s] 26%|██▌       | 408/1600 [03:18<10:16,  1.93it/s] 26%|██▌       | 411/1600 [03:18<07:26,  2.66it/s] 26%|██▌       | 414/1600 [03:18<05:26,  3.63it/s] 26%|██▌       | 417/1600 [03:18<04:03,  4.85it/s] 26%|██▋       | 420/1600 [03:18<03:03,  6.45it/s]                                                   26%|██▋       | 420/1600 [03:18<03:03,  6.45it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.53it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.42it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.42it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.28it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.11it/s][A                                                  
                                               [A 26%|██▋       | 420/1600 [03:19<03:03,  6.45it/s]
100%|██████████| 20/20 [00:00<00:00, 27.11it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-420
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-420/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-420/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-400] due to args.save_total_limit
 26%|██▋       | 423/1600 [03:27<19:52,  1.01s/it] 27%|██▋       | 426/1600 [03:28<14:08,  1.38it/s] 27%|██▋       | 429/1600 [03:28<10:08,  1.92it/s] 27%|██▋       | 432/1600 [03:28<07:20,  2.65it/s] 27%|██▋       | 435/1600 [03:28<05:23,  3.61it/s] 27%|██▋       | 438/1600 [03:28<04:01,  4.82it/s]                                                   28%|██▊       | 440/1600 [03:28<04:00,  4.82it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.27it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.36it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.91it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.22it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.08it/s][A                                                  
                                               [A 28%|██▊       | 440/1600 [03:29<04:00,  4.82it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-440
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-440/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-440/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-420] due to args.save_total_limit
 28%|██▊       | 441/1600 [03:37<20:08,  1.04s/it] 28%|██▊       | 443/1600 [03:37<15:51,  1.22it/s] 28%|██▊       | 446/1600 [03:37<11:00,  1.75it/s] 28%|██▊       | 449/1600 [03:37<07:46,  2.47it/s] 28%|██▊       | 452/1600 [03:38<05:36,  3.41it/s] 28%|██▊       | 455/1600 [03:38<04:07,  4.63it/s] 29%|██▊       | 458/1600 [03:38<03:05,  6.17it/s]                                                   29%|██▉       | 460/1600 [03:38<03:04,  6.17it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.74it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.56it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.04it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.52it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                  
                                               [A 29%|██▉       | 460/1600 [03:39<03:04,  6.17it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-460
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-460/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-460/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-440] due to args.save_total_limit
 29%|██▉       | 461/1600 [03:47<19:24,  1.02s/it] 29%|██▉       | 463/1600 [03:47<15:14,  1.24it/s] 29%|██▉       | 466/1600 [03:47<10:32,  1.79it/s] 29%|██▉       | 469/1600 [03:47<07:26,  2.53it/s] 30%|██▉       | 472/1600 [03:47<05:23,  3.49it/s] 30%|██▉       | 475/1600 [03:47<03:57,  4.74it/s] 30%|██▉       | 478/1600 [03:48<03:00,  6.23it/s]                                                   30%|███       | 480/1600 [03:48<02:59,  6.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.59it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.39it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.86it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.23it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 26.95it/s][A                                                  
                                               [A 30%|███       | 480/1600 [03:49<02:59,  6.23it/s]
100%|██████████| 20/20 [00:00<00:00, 26.95it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-480
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-480/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-480/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-460] due to args.save_total_limit
 30%|███       | 481/1600 [03:57<19:01,  1.02s/it] 30%|███       | 483/1600 [03:57<14:57,  1.24it/s] 30%|███       | 485/1600 [03:57<11:32,  1.61it/s] 30%|███       | 488/1600 [03:57<07:52,  2.35it/s] 31%|███       | 491/1600 [03:57<05:33,  3.33it/s] 31%|███       | 494/1600 [03:57<04:01,  4.58it/s] 31%|███       | 497/1600 [03:57<03:01,  6.09it/s] 31%|███▏      | 500/1600 [03:57<02:17,  8.00it/s]                                                   31%|███▏      | 500/1600 [03:57<02:17,  8.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.32it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.32it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.87it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.39it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.18it/s][A                                                  
                                               [A 31%|███▏      | 500/1600 [03:58<02:17,  8.00it/s]
100%|██████████| 20/20 [00:00<00:00, 27.18it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-500/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-500/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-480] due to args.save_total_limit
 31%|███▏      | 503/1600 [04:06<18:26,  1.01s/it] 32%|███▏      | 506/1600 [04:07<13:02,  1.40it/s] 32%|███▏      | 509/1600 [04:07<09:18,  1.95it/s] 32%|███▏      | 512/1600 [04:07<06:44,  2.69it/s] 32%|███▏      | 515/1600 [04:07<04:56,  3.66it/s] 32%|███▏      | 518/1600 [04:07<03:39,  4.92it/s]                                                   32%|███▎      | 520/1600 [04:07<03:39,  4.92it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.48it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.40it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.94it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.44it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.24it/s][A                                                  
                                               [A 32%|███▎      | 520/1600 [04:08<03:39,  4.92it/s]
100%|██████████| 20/20 [00:00<00:00, 27.24it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-520
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-520/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-520/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-500] due to args.save_total_limit
 33%|███▎      | 521/1600 [04:16<18:32,  1.03s/it] 33%|███▎      | 524/1600 [04:16<13:11,  1.36it/s] 33%|███▎      | 527/1600 [04:16<09:26,  1.89it/s] 33%|███▎      | 530/1600 [04:16<06:50,  2.61it/s] 33%|███▎      | 533/1600 [04:17<04:59,  3.56it/s] 34%|███▎      | 536/1600 [04:17<03:44,  4.75it/s] 34%|███▎      | 539/1600 [04:17<02:50,  6.24it/s]                                                   34%|███▍      | 540/1600 [04:17<02:49,  6.24it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.55it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.46it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.93it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.37it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.16it/s][A                                                  
                                               [A 34%|███▍      | 540/1600 [04:18<02:49,  6.24it/s]
100%|██████████| 20/20 [00:00<00:00, 27.16it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-540
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-540/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-540/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-520] due to args.save_total_limit
 34%|███▍      | 542/1600 [04:26<17:46,  1.01s/it] 34%|███▍      | 545/1600 [04:26<12:39,  1.39it/s] 34%|███▍      | 548/1600 [04:26<09:04,  1.93it/s] 34%|███▍      | 551/1600 [04:26<06:32,  2.67it/s] 35%|███▍      | 554/1600 [04:26<04:48,  3.63it/s] 35%|███▍      | 557/1600 [04:26<03:35,  4.84it/s] 35%|███▌      | 560/1600 [04:27<02:42,  6.41it/s]                                                   35%|███▌      | 560/1600 [04:27<02:42,  6.41it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.51it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.33it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.08it/s][A                                                  
                                               [A 35%|███▌      | 560/1600 [04:28<02:42,  6.41it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-560
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-560/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-560/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-540] due to args.save_total_limit
 35%|███▌      | 563/1600 [04:36<17:36,  1.02s/it] 35%|███▌      | 566/1600 [04:36<12:32,  1.37it/s] 36%|███▌      | 569/1600 [04:36<08:59,  1.91it/s] 36%|███▌      | 572/1600 [04:36<06:30,  2.63it/s] 36%|███▌      | 575/1600 [04:36<04:46,  3.58it/s] 36%|███▌      | 578/1600 [04:36<03:33,  4.79it/s]                                                   36%|███▋      | 580/1600 [04:36<03:32,  4.79it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.73it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.59it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.12it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.61it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.39it/s][A                                                  
                                               [A 36%|███▋      | 580/1600 [04:37<03:32,  4.79it/s]
100%|██████████| 20/20 [00:00<00:00, 27.39it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-580
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-580/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-580/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-560] due to args.save_total_limit
 36%|███▋      | 581/1600 [04:45<17:51,  1.05s/it] 36%|███▋      | 584/1600 [04:46<12:43,  1.33it/s] 37%|███▋      | 587/1600 [04:46<09:07,  1.85it/s] 37%|███▋      | 590/1600 [04:46<06:36,  2.55it/s] 37%|███▋      | 593/1600 [04:46<04:49,  3.48it/s] 37%|███▋      | 596/1600 [04:46<03:34,  4.68it/s] 37%|███▋      | 599/1600 [04:46<02:43,  6.14it/s]                                                   38%|███▊      | 600/1600 [04:46<02:42,  6.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.78it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.63it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.15it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.56it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.28it/s][A                                                  
                                               [A 38%|███▊      | 600/1600 [04:47<02:42,  6.14it/s]
100%|██████████| 20/20 [00:00<00:00, 27.28it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-600
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-600/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-600/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-580] due to args.save_total_limit
 38%|███▊      | 602/1600 [04:55<16:40,  1.00s/it] 38%|███▊      | 604/1600 [04:55<13:08,  1.26it/s] 38%|███▊      | 607/1600 [04:55<09:07,  1.81it/s] 38%|███▊      | 610/1600 [04:55<06:27,  2.55it/s] 38%|███▊      | 613/1600 [04:56<04:39,  3.53it/s] 38%|███▊      | 616/1600 [04:56<03:26,  4.77it/s] 39%|███▊      | 619/1600 [04:56<02:36,  6.26it/s]                                                   39%|███▉      | 620/1600 [04:56<02:36,  6.26it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.56it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.44it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.97it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.50it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.26it/s][A                                                  
                                               [A 39%|███▉      | 620/1600 [04:57<02:36,  6.26it/s]
100%|██████████| 20/20 [00:00<00:00, 27.26it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-620
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-620/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-620/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-600] due to args.save_total_limit
 39%|███▉      | 622/1600 [05:05<16:47,  1.03s/it] 39%|███▉      | 625/1600 [05:05<11:54,  1.36it/s] 39%|███▉      | 628/1600 [05:05<08:30,  1.91it/s] 39%|███▉      | 631/1600 [05:05<06:09,  2.62it/s] 40%|███▉      | 634/1600 [05:06<04:30,  3.57it/s] 40%|███▉      | 637/1600 [05:06<03:20,  4.81it/s] 40%|████      | 640/1600 [05:06<02:30,  6.38it/s]                                                   40%|████      | 640/1600 [05:06<02:30,  6.38it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.43it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.36it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.64it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.33it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.15it/s][A                                                  
                                               [A 40%|████      | 640/1600 [05:07<02:30,  6.38it/s]
100%|██████████| 20/20 [00:00<00:00, 27.15it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-640
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-640/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-640/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-620] due to args.save_total_limit
 40%|████      | 643/1600 [05:15<16:05,  1.01s/it] 40%|████      | 646/1600 [05:15<11:26,  1.39it/s] 41%|████      | 649/1600 [05:15<08:10,  1.94it/s] 41%|████      | 652/1600 [05:15<05:55,  2.67it/s] 41%|████      | 655/1600 [05:15<04:20,  3.62it/s] 41%|████      | 658/1600 [05:15<03:14,  4.84it/s]                                                   41%|████▏     | 660/1600 [05:16<03:14,  4.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.59it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.39it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.89it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.40it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                  
                                               [A 41%|████▏     | 660/1600 [05:16<03:14,  4.84it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-660
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-660/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-660/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-640] due to args.save_total_limit
 41%|████▏     | 661/1600 [05:25<16:49,  1.07s/it] 42%|████▏     | 664/1600 [05:25<11:57,  1.30it/s] 42%|████▏     | 667/1600 [05:25<08:33,  1.82it/s] 42%|████▏     | 670/1600 [05:25<06:10,  2.51it/s] 42%|████▏     | 673/1600 [05:25<04:31,  3.41it/s] 42%|████▏     | 676/1600 [05:25<03:22,  4.57it/s] 42%|████▏     | 679/1600 [05:26<02:33,  5.98it/s]                                                   42%|████▎     | 680/1600 [05:26<02:33,  5.98it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 35.87it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.54it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.36it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.33it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.21it/s][A                                                  
                                               [A 42%|████▎     | 680/1600 [05:27<02:33,  5.98it/s]
100%|██████████| 20/20 [00:00<00:00, 27.21it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-680
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-680/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-680/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-660] due to args.save_total_limit
 43%|████▎     | 682/1600 [05:35<15:38,  1.02s/it] 43%|████▎     | 685/1600 [05:35<11:07,  1.37it/s] 43%|████▎     | 688/1600 [05:35<07:58,  1.91it/s] 43%|████▎     | 691/1600 [05:35<05:46,  2.63it/s] 43%|████▎     | 694/1600 [05:35<04:13,  3.57it/s] 44%|████▎     | 697/1600 [05:35<03:08,  4.80it/s] 44%|████▍     | 700/1600 [05:35<02:21,  6.35it/s]                                                   44%|████▍     | 700/1600 [05:35<02:21,  6.35it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.56it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.44it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.96it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.50it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.24it/s][A                                                  
                                               [A 44%|████▍     | 700/1600 [05:36<02:21,  6.35it/s]
100%|██████████| 20/20 [00:00<00:00, 27.24it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-700
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-700/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-700/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-680] due to args.save_total_limit
 44%|████▍     | 703/1600 [05:44<15:10,  1.01s/it] 44%|████▍     | 706/1600 [05:45<10:47,  1.38it/s] 44%|████▍     | 709/1600 [05:45<07:43,  1.92it/s] 44%|████▍     | 712/1600 [05:45<05:35,  2.65it/s] 45%|████▍     | 715/1600 [05:45<04:05,  3.61it/s] 45%|████▍     | 718/1600 [05:45<03:02,  4.83it/s]                                                   45%|████▌     | 720/1600 [05:45<03:02,  4.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.69it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.55it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.00it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.46it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.20it/s][A                                                  
                                               [A 45%|████▌     | 720/1600 [05:46<03:02,  4.83it/s]
100%|██████████| 20/20 [00:00<00:00, 27.20it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-720
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-720/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-720/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-700] due to args.save_total_limit
 45%|████▌     | 721/1600 [05:54<15:12,  1.04s/it] 45%|████▌     | 723/1600 [05:54<11:57,  1.22it/s] 45%|████▌     | 726/1600 [05:54<08:17,  1.76it/s] 46%|████▌     | 729/1600 [05:54<05:51,  2.48it/s] 46%|████▌     | 732/1600 [05:55<04:13,  3.42it/s] 46%|████▌     | 735/1600 [05:55<03:06,  4.64it/s] 46%|████▌     | 738/1600 [05:55<02:20,  6.13it/s]                                                   46%|████▋     | 740/1600 [05:55<02:20,  6.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.29it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.28it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.81it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.39it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.21it/s][A                                                  
                                               [A 46%|████▋     | 740/1600 [05:56<02:20,  6.13it/s]
100%|██████████| 20/20 [00:00<00:00, 27.21it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-740
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-740/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-740/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-720] due to args.save_total_limit
 46%|████▋     | 741/1600 [06:04<14:52,  1.04s/it] 46%|████▋     | 743/1600 [06:04<11:40,  1.22it/s] 47%|████▋     | 745/1600 [06:04<08:59,  1.58it/s] 47%|████▋     | 748/1600 [06:04<06:06,  2.32it/s] 47%|████▋     | 751/1600 [06:04<04:17,  3.29it/s] 47%|████▋     | 754/1600 [06:05<03:07,  4.52it/s] 47%|████▋     | 757/1600 [06:05<02:19,  6.04it/s] 48%|████▊     | 760/1600 [06:05<01:45,  7.98it/s]                                                   48%|████▊     | 760/1600 [06:05<01:45,  7.98it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.38it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.29it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.85it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.39it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.20it/s][A                                                  
                                               [A 48%|████▊     | 760/1600 [06:06<01:45,  7.98it/s]
100%|██████████| 20/20 [00:00<00:00, 27.20it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-760
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-760/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-760/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-740] due to args.save_total_limit
 48%|████▊     | 763/1600 [06:14<14:05,  1.01s/it] 48%|████▊     | 766/1600 [06:14<09:58,  1.39it/s] 48%|████▊     | 769/1600 [06:14<07:06,  1.95it/s] 48%|████▊     | 772/1600 [06:14<05:08,  2.69it/s] 48%|████▊     | 775/1600 [06:14<03:45,  3.66it/s] 49%|████▊     | 778/1600 [06:14<02:48,  4.89it/s]                                                   49%|████▉     | 780/1600 [06:15<02:47,  4.89it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.84it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.53it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.05it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.40it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.13it/s][A                                                  
                                               [A 49%|████▉     | 780/1600 [06:16<02:47,  4.89it/s]
100%|██████████| 20/20 [00:00<00:00, 27.13it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-780
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-780/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-780/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-760] due to args.save_total_limit
 49%|████▉     | 781/1600 [06:23<13:57,  1.02s/it] 49%|████▉     | 784/1600 [06:23<09:55,  1.37it/s] 49%|████▉     | 787/1600 [06:24<07:05,  1.91it/s] 49%|████▉     | 790/1600 [06:24<05:08,  2.63it/s] 50%|████▉     | 793/1600 [06:24<03:45,  3.58it/s] 50%|████▉     | 796/1600 [06:24<02:48,  4.77it/s] 50%|████▉     | 799/1600 [06:24<02:08,  6.22it/s]                                                   50%|█████     | 800/1600 [06:24<02:08,  6.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.24it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.30it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.08it/s][A                                                  
                                               [A 50%|█████     | 800/1600 [06:25<02:08,  6.22it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-800
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-800/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-800/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-780] due to args.save_total_limit
 50%|█████     | 802/1600 [06:33<13:20,  1.00s/it] 50%|█████     | 804/1600 [06:33<10:30,  1.26it/s] 50%|█████     | 807/1600 [06:33<07:16,  1.82it/s] 51%|█████     | 810/1600 [06:33<05:08,  2.56it/s] 51%|█████     | 813/1600 [06:33<03:42,  3.54it/s] 51%|█████     | 816/1600 [06:34<02:44,  4.77it/s] 51%|█████     | 819/1600 [06:34<02:04,  6.29it/s]                                                   51%|█████▏    | 820/1600 [06:34<02:03,  6.29it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.55it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.28it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.16it/s][A                                                  
                                               [A 51%|█████▏    | 820/1600 [06:35<02:03,  6.29it/s]
100%|██████████| 20/20 [00:00<00:00, 27.16it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-820
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-820/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-820/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-800] due to args.save_total_limit
 51%|█████▏    | 822/1600 [06:43<13:17,  1.02s/it] 52%|█████▏    | 824/1600 [06:43<10:25,  1.24it/s] 52%|█████▏    | 827/1600 [06:43<07:12,  1.79it/s] 52%|█████▏    | 830/1600 [06:43<05:05,  2.52it/s] 52%|█████▏    | 833/1600 [06:43<03:39,  3.50it/s] 52%|█████▏    | 836/1600 [06:43<02:41,  4.74it/s] 52%|█████▏    | 839/1600 [06:44<02:01,  6.24it/s]                                                   52%|█████▎    | 840/1600 [06:44<02:01,  6.24it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.74it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.53it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.12it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.61it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.39it/s][A                                                  
                                               [A 52%|█████▎    | 840/1600 [06:45<02:01,  6.24it/s]
100%|██████████| 20/20 [00:00<00:00, 27.39it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-840
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-840/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-840/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-820] due to args.save_total_limit
 53%|█████▎    | 842/1600 [06:53<12:52,  1.02s/it] 53%|█████▎    | 845/1600 [06:53<09:07,  1.38it/s] 53%|█████▎    | 848/1600 [06:53<06:30,  1.92it/s] 53%|█████▎    | 851/1600 [06:53<04:41,  2.66it/s] 53%|█████▎    | 854/1600 [06:53<03:26,  3.62it/s] 54%|█████▎    | 857/1600 [06:53<02:33,  4.84it/s] 54%|█████▍    | 860/1600 [06:53<01:55,  6.43it/s]                                                   54%|█████▍    | 860/1600 [06:53<01:55,  6.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.43it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.32it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.86it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.09it/s][A                                                  
                                               [A 54%|█████▍    | 860/1600 [06:54<01:55,  6.43it/s]
100%|██████████| 20/20 [00:00<00:00, 27.09it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-860
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-860/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-860/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-840] due to args.save_total_limit
 54%|█████▍    | 863/1600 [07:02<12:21,  1.01s/it] 54%|█████▍    | 865/1600 [07:02<09:43,  1.26it/s] 54%|█████▍    | 868/1600 [07:02<06:43,  1.81it/s] 54%|█████▍    | 871/1600 [07:03<04:45,  2.55it/s] 55%|█████▍    | 874/1600 [07:03<03:26,  3.52it/s] 55%|█████▍    | 877/1600 [07:03<02:32,  4.73it/s] 55%|█████▌    | 880/1600 [07:03<01:53,  6.33it/s]                                                   55%|█████▌    | 880/1600 [07:03<01:53,  6.33it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 35.31it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.97it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.66it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.59it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.37it/s][A                                                  
                                               [A 55%|█████▌    | 880/1600 [07:04<01:53,  6.33it/s]
100%|██████████| 20/20 [00:00<00:00, 27.37it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-880
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-880/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-880/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-860] due to args.save_total_limit
 55%|█████▌    | 883/1600 [07:12<12:04,  1.01s/it] 55%|█████▌    | 886/1600 [07:12<08:33,  1.39it/s] 56%|█████▌    | 889/1600 [07:12<06:06,  1.94it/s] 56%|█████▌    | 892/1600 [07:12<04:24,  2.67it/s] 56%|█████▌    | 895/1600 [07:12<03:13,  3.63it/s] 56%|█████▌    | 898/1600 [07:13<02:24,  4.85it/s]                                                   56%|█████▋    | 900/1600 [07:13<02:24,  4.85it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.57it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.37it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.87it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.41it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.17it/s][A                                                  
                                               [A 56%|█████▋    | 900/1600 [07:14<02:24,  4.85it/s]
100%|██████████| 20/20 [00:00<00:00, 27.17it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-900
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-900/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-900/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-880] due to args.save_total_limit
 56%|█████▋    | 901/1600 [07:22<12:17,  1.05s/it] 56%|█████▋    | 903/1600 [07:22<09:39,  1.20it/s] 57%|█████▋    | 906/1600 [07:22<06:40,  1.73it/s] 57%|█████▋    | 909/1600 [07:22<04:42,  2.45it/s] 57%|█████▋    | 912/1600 [07:22<03:23,  3.38it/s] 57%|█████▋    | 915/1600 [07:22<02:29,  4.57it/s] 57%|█████▋    | 918/1600 [07:22<01:52,  6.06it/s]                                                   57%|█████▊    | 920/1600 [07:23<01:52,  6.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.71it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.49it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.03it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.38it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.05it/s][A                                                  
                                               [A 57%|█████▊    | 920/1600 [07:24<01:52,  6.06it/s]
100%|██████████| 20/20 [00:00<00:00, 27.05it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-920
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-920/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-920/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-900] due to args.save_total_limit
 58%|█████▊    | 921/1600 [07:31<11:37,  1.03s/it] 58%|█████▊    | 923/1600 [07:32<09:07,  1.24it/s] 58%|█████▊    | 926/1600 [07:32<06:17,  1.78it/s] 58%|█████▊    | 929/1600 [07:32<04:26,  2.52it/s] 58%|█████▊    | 932/1600 [07:32<03:12,  3.48it/s] 58%|█████▊    | 935/1600 [07:32<02:20,  4.72it/s] 59%|█████▊    | 938/1600 [07:32<01:46,  6.21it/s]                                                   59%|█████▉    | 940/1600 [07:32<01:46,  6.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.15it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.31it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.08it/s][A                                                  
                                               [A 59%|█████▉    | 940/1600 [07:33<01:46,  6.21it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-940
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-940/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-940/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-920] due to args.save_total_limit
 59%|█████▉    | 941/1600 [07:41<11:18,  1.03s/it] 59%|█████▉    | 943/1600 [07:41<08:52,  1.23it/s] 59%|█████▉    | 946/1600 [07:42<06:07,  1.78it/s] 59%|█████▉    | 949/1600 [07:42<04:18,  2.52it/s] 60%|█████▉    | 952/1600 [07:42<03:06,  3.47it/s] 60%|█████▉    | 955/1600 [07:42<02:17,  4.69it/s] 60%|█████▉    | 958/1600 [07:42<01:43,  6.17it/s]                                                   60%|██████    | 960/1600 [07:42<01:43,  6.17it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.49it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.29it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.91it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.43it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                  
                                               [A 60%|██████    | 960/1600 [07:43<01:43,  6.17it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-960
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-960/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-960/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-940] due to args.save_total_limit
 60%|██████    | 961/1600 [07:51<10:55,  1.03s/it] 60%|██████    | 963/1600 [07:51<08:34,  1.24it/s] 60%|██████    | 966/1600 [07:51<05:55,  1.78it/s] 61%|██████    | 969/1600 [07:51<04:10,  2.52it/s] 61%|██████    | 972/1600 [07:52<03:00,  3.47it/s] 61%|██████    | 975/1600 [07:52<02:13,  4.69it/s] 61%|██████    | 978/1600 [07:52<01:40,  6.21it/s]                                                   61%|██████▏   | 980/1600 [07:52<01:39,  6.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.56it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.41it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.06it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.60it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                  
                                               [A 61%|██████▏   | 980/1600 [07:53<01:39,  6.21it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-980
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-980/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-980/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-960] due to args.save_total_limit
 61%|██████▏   | 981/1600 [08:01<10:31,  1.02s/it] 61%|██████▏   | 983/1600 [08:01<08:15,  1.25it/s] 62%|██████▏   | 986/1600 [08:01<05:42,  1.79it/s] 62%|██████▏   | 989/1600 [08:01<04:01,  2.53it/s] 62%|██████▏   | 992/1600 [08:01<02:53,  3.50it/s] 62%|██████▏   | 995/1600 [08:01<02:07,  4.73it/s] 62%|██████▏   | 998/1600 [08:02<01:36,  6.24it/s]                                                   62%|██████▎   | 1000/1600 [08:02<01:36,  6.24it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.33it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.20it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.77it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.31it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.08it/s][A                                                   
                                               [A 62%|██████▎   | 1000/1600 [08:03<01:36,  6.24it/s]
100%|██████████| 20/20 [00:00<00:00, 27.08it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1000/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1000/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-980] due to args.save_total_limit
 63%|██████▎   | 1001/1600 [08:11<10:10,  1.02s/it] 63%|██████▎   | 1003/1600 [08:11<07:58,  1.25it/s] 63%|██████▎   | 1005/1600 [08:11<06:08,  1.61it/s] 63%|██████▎   | 1008/1600 [08:11<04:10,  2.37it/s] 63%|██████▎   | 1011/1600 [08:11<02:56,  3.35it/s] 63%|██████▎   | 1014/1600 [08:11<02:07,  4.58it/s] 64%|██████▎   | 1017/1600 [08:11<01:36,  6.05it/s] 64%|██████▍   | 1020/1600 [08:11<01:13,  7.93it/s]                                                    64%|██████▍   | 1020/1600 [08:12<01:13,  7.93it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.49it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.44it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.03it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.52it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.28it/s][A                                                   
                                               [A 64%|██████▍   | 1020/1600 [08:12<01:13,  7.93it/s]
100%|██████████| 20/20 [00:00<00:00, 27.28it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1020
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1020/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1020/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1000] due to args.save_total_limit
 64%|██████▍   | 1023/1600 [08:20<09:43,  1.01s/it] 64%|██████▍   | 1026/1600 [08:21<06:52,  1.39it/s] 64%|██████▍   | 1029/1600 [08:21<04:53,  1.95it/s] 64%|██████▍   | 1032/1600 [08:21<03:31,  2.69it/s] 65%|██████▍   | 1035/1600 [08:21<02:34,  3.67it/s] 65%|██████▍   | 1038/1600 [08:21<01:54,  4.89it/s]                                                    65%|██████▌   | 1040/1600 [08:21<01:54,  4.89it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.78it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.56it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.13it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.66it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.45it/s][A                                                   
                                               [A 65%|██████▌   | 1040/1600 [08:22<01:54,  4.89it/s]
100%|██████████| 20/20 [00:00<00:00, 27.45it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1040
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1040/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1040/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1020] due to args.save_total_limit
 65%|██████▌   | 1041/1600 [08:30<09:49,  1.05s/it] 65%|██████▌   | 1043/1600 [08:30<07:43,  1.20it/s] 65%|██████▌   | 1046/1600 [08:31<05:20,  1.73it/s] 66%|██████▌   | 1049/1600 [08:31<03:44,  2.45it/s] 66%|██████▌   | 1052/1600 [08:31<02:42,  3.38it/s] 66%|██████▌   | 1055/1600 [08:31<01:59,  4.56it/s] 66%|██████▌   | 1058/1600 [08:31<01:29,  6.03it/s]                                                    66%|██████▋   | 1060/1600 [08:31<01:29,  6.03it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.42it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.05it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.62it/s][A
 80%|████████  | 16/20 [00:00<00:00, 27.87it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 26.79it/s][A                                                   
                                               [A 66%|██████▋   | 1060/1600 [08:32<01:29,  6.03it/s]
100%|██████████| 20/20 [00:00<00:00, 26.79it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1060
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1060/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1060/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1040] due to args.save_total_limit
 66%|██████▋   | 1061/1600 [08:40<09:15,  1.03s/it] 66%|██████▋   | 1063/1600 [08:40<07:15,  1.23it/s] 67%|██████▋   | 1066/1600 [08:40<05:00,  1.78it/s] 67%|██████▋   | 1069/1600 [08:40<03:31,  2.51it/s] 67%|██████▋   | 1072/1600 [08:41<02:32,  3.46it/s] 67%|██████▋   | 1075/1600 [08:41<01:52,  4.68it/s] 67%|██████▋   | 1078/1600 [08:41<01:24,  6.20it/s]                                                    68%|██████▊   | 1080/1600 [08:41<01:23,  6.20it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.47it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.35it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.87it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.27it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.13it/s][A                                                   
                                               [A 68%|██████▊   | 1080/1600 [08:42<01:23,  6.20it/s]
100%|██████████| 20/20 [00:00<00:00, 27.13it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1080
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1080/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1080/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1060] due to args.save_total_limit
 68%|██████▊   | 1081/1600 [08:50<08:49,  1.02s/it] 68%|██████▊   | 1084/1600 [08:50<06:14,  1.38it/s] 68%|██████▊   | 1087/1600 [08:50<04:27,  1.92it/s] 68%|██████▊   | 1090/1600 [08:50<03:12,  2.65it/s] 68%|██████▊   | 1093/1600 [08:50<02:21,  3.59it/s] 68%|██████▊   | 1096/1600 [08:51<01:44,  4.81it/s] 69%|██████▊   | 1099/1600 [08:51<01:19,  6.32it/s]                                                    69%|██████▉   | 1100/1600 [08:51<01:19,  6.32it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.62it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.46it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.03it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.54it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                   
                                               [A 69%|██████▉   | 1100/1600 [08:52<01:19,  6.32it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1100
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1100/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1100/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1080] due to args.save_total_limit
 69%|██████▉   | 1102/1600 [09:00<08:19,  1.00s/it] 69%|██████▉   | 1104/1600 [09:00<06:32,  1.26it/s] 69%|██████▉   | 1107/1600 [09:00<04:31,  1.81it/s] 69%|██████▉   | 1110/1600 [09:00<03:11,  2.56it/s] 70%|██████▉   | 1113/1600 [09:00<02:17,  3.53it/s] 70%|██████▉   | 1116/1600 [09:00<01:41,  4.77it/s] 70%|██████▉   | 1119/1600 [09:00<01:16,  6.27it/s]                                                    70%|███████   | 1120/1600 [09:00<01:16,  6.27it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.77it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.60it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.13it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.59it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.28it/s][A                                                   
                                               [A 70%|███████   | 1120/1600 [09:01<01:16,  6.27it/s]
100%|██████████| 20/20 [00:00<00:00, 27.28it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1120
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1120/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1120/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1100] due to args.save_total_limit
 70%|███████   | 1122/1600 [09:09<08:05,  1.02s/it] 70%|███████   | 1125/1600 [09:09<05:43,  1.38it/s] 70%|███████   | 1128/1600 [09:10<04:05,  1.92it/s] 71%|███████   | 1131/1600 [09:10<02:56,  2.66it/s] 71%|███████   | 1134/1600 [09:10<02:08,  3.62it/s] 71%|███████   | 1137/1600 [09:10<01:35,  4.83it/s] 71%|███████▏  | 1140/1600 [09:10<01:12,  6.34it/s]                                                    71%|███████▏  | 1140/1600 [09:10<01:12,  6.34it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.58it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.39it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.89it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.46it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.22it/s][A                                                   
                                               [A 71%|███████▏  | 1140/1600 [09:11<01:12,  6.34it/s]
100%|██████████| 20/20 [00:00<00:00, 27.22it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1140
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1140/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1140/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1120] due to args.save_total_limit
 71%|███████▏  | 1143/1600 [09:19<07:43,  1.01s/it] 72%|███████▏  | 1146/1600 [09:19<05:28,  1.38it/s] 72%|███████▏  | 1149/1600 [09:19<03:54,  1.93it/s] 72%|███████▏  | 1152/1600 [09:20<02:49,  2.65it/s] 72%|███████▏  | 1155/1600 [09:20<02:03,  3.60it/s] 72%|███████▏  | 1158/1600 [09:20<01:31,  4.83it/s]                                                    72%|███████▎  | 1160/1600 [09:20<01:31,  4.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.42it/s][A
 40%|████      | 8/20 [00:00<00:00, 29.70it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.05it/s][A
 75%|███████▌  | 15/20 [00:00<00:00, 28.21it/s][A
 90%|█████████ | 18/20 [00:00<00:00, 27.16it/s][A                                                   
                                               [A 72%|███████▎  | 1160/1600 [09:21<01:31,  4.83it/s]
100%|██████████| 20/20 [00:00<00:00, 27.16it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1160
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1160/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1160/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1140] due to args.save_total_limit
 73%|███████▎  | 1161/1600 [09:29<07:40,  1.05s/it] 73%|███████▎  | 1164/1600 [09:29<05:26,  1.33it/s] 73%|███████▎  | 1167/1600 [09:29<03:53,  1.86it/s] 73%|███████▎  | 1170/1600 [09:29<02:47,  2.56it/s] 73%|███████▎  | 1173/1600 [09:29<02:02,  3.49it/s] 74%|███████▎  | 1176/1600 [09:30<01:30,  4.67it/s] 74%|███████▎  | 1179/1600 [09:30<01:08,  6.15it/s]                                                    74%|███████▍  | 1180/1600 [09:30<01:08,  6.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.89it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.61it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.10it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.61it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                   
                                               [A 74%|███████▍  | 1180/1600 [09:31<01:08,  6.15it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1180
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1180/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1180/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1160] due to args.save_total_limit
 74%|███████▍  | 1182/1600 [09:39<07:00,  1.01s/it] 74%|███████▍  | 1185/1600 [09:39<04:58,  1.39it/s] 74%|███████▍  | 1188/1600 [09:39<03:32,  1.93it/s] 74%|███████▍  | 1191/1600 [09:39<02:33,  2.66it/s] 75%|███████▍  | 1194/1600 [09:39<01:51,  3.63it/s] 75%|███████▍  | 1197/1600 [09:39<01:23,  4.85it/s] 75%|███████▌  | 1200/1600 [09:39<01:02,  6.40it/s]                                                    75%|███████▌  | 1200/1600 [09:39<01:02,  6.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.62it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.47it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.00it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.44it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.21it/s][A                                                   
                                               [A 75%|███████▌  | 1200/1600 [09:40<01:02,  6.40it/s]
100%|██████████| 20/20 [00:00<00:00, 27.21it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1200
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1200/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1200/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1180] due to args.save_total_limit
 75%|███████▌  | 1203/1600 [09:48<06:35,  1.00it/s] 75%|███████▌  | 1206/1600 [09:48<04:40,  1.41it/s] 76%|███████▌  | 1209/1600 [09:49<03:19,  1.96it/s] 76%|███████▌  | 1212/1600 [09:49<02:23,  2.70it/s] 76%|███████▌  | 1215/1600 [09:49<01:44,  3.68it/s] 76%|███████▌  | 1218/1600 [09:49<01:17,  4.90it/s]                                                    76%|███████▋  | 1220/1600 [09:49<01:17,  4.90it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.23it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.34it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.93it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.46it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.28it/s][A                                                   
                                               [A 76%|███████▋  | 1220/1600 [09:50<01:17,  4.90it/s]
100%|██████████| 20/20 [00:00<00:00, 27.28it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1220
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1220/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1220/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1200] due to args.save_total_limit
 76%|███████▋  | 1221/1600 [09:58<06:29,  1.03s/it] 76%|███████▋  | 1223/1600 [09:58<05:05,  1.23it/s] 77%|███████▋  | 1226/1600 [09:58<03:30,  1.77it/s] 77%|███████▋  | 1229/1600 [09:58<02:28,  2.50it/s] 77%|███████▋  | 1232/1600 [09:58<01:46,  3.45it/s] 77%|███████▋  | 1235/1600 [09:58<01:18,  4.65it/s] 77%|███████▋  | 1238/1600 [09:59<00:59,  6.13it/s]                                                    78%|███████▊  | 1240/1600 [09:59<00:58,  6.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.51it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.36it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.89it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.34it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.12it/s][A                                                   
                                               [A 78%|███████▊  | 1240/1600 [10:00<00:58,  6.13it/s]
100%|██████████| 20/20 [00:00<00:00, 27.12it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1240
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1240/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1240/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1220] due to args.save_total_limit
 78%|███████▊  | 1241/1600 [10:08<06:22,  1.07s/it] 78%|███████▊  | 1243/1600 [10:08<04:59,  1.19it/s] 78%|███████▊  | 1245/1600 [10:08<03:49,  1.54it/s] 78%|███████▊  | 1248/1600 [10:08<02:35,  2.27it/s] 78%|███████▊  | 1251/1600 [10:08<01:48,  3.21it/s] 78%|███████▊  | 1254/1600 [10:09<01:18,  4.42it/s] 79%|███████▊  | 1257/1600 [10:09<00:58,  5.88it/s] 79%|███████▉  | 1260/1600 [10:09<00:43,  7.79it/s]                                                    79%|███████▉  | 1260/1600 [10:09<00:43,  7.79it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.49it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.36it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.93it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.45it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.24it/s][A                                                   
                                               [A 79%|███████▉  | 1260/1600 [10:10<00:43,  7.79it/s]
100%|██████████| 20/20 [00:00<00:00, 27.24it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1260
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1260/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1260/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1240] due to args.save_total_limit
 79%|███████▉  | 1263/1600 [10:18<05:50,  1.04s/it] 79%|███████▉  | 1266/1600 [10:18<04:06,  1.36it/s] 79%|███████▉  | 1269/1600 [10:18<02:54,  1.90it/s] 80%|███████▉  | 1272/1600 [10:19<02:04,  2.63it/s] 80%|███████▉  | 1275/1600 [10:19<01:30,  3.58it/s] 80%|███████▉  | 1278/1600 [10:19<01:07,  4.80it/s]                                                    80%|████████  | 1280/1600 [10:19<01:06,  4.80it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.56it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.38it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.79it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.27it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.07it/s][A                                                   
                                               [A 80%|████████  | 1280/1600 [10:20<01:06,  4.80it/s]
100%|██████████| 20/20 [00:00<00:00, 27.07it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1280
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1280/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1280/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1260] due to args.save_total_limit
 80%|████████  | 1281/1600 [10:28<05:31,  1.04s/it] 80%|████████  | 1284/1600 [10:28<03:54,  1.35it/s] 80%|████████  | 1287/1600 [10:28<02:46,  1.88it/s] 81%|████████  | 1290/1600 [10:28<01:59,  2.58it/s] 81%|████████  | 1293/1600 [10:28<01:26,  3.53it/s] 81%|████████  | 1296/1600 [10:28<01:04,  4.74it/s] 81%|████████  | 1299/1600 [10:29<00:48,  6.21it/s]                                                    81%|████████▏ | 1300/1600 [10:29<00:48,  6.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.38it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.28it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.81it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.32it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.02it/s][A                                                   
                                               [A 81%|████████▏ | 1300/1600 [10:30<00:48,  6.21it/s]
100%|██████████| 20/20 [00:00<00:00, 27.02it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1300
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1300/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1300/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1280] due to args.save_total_limit
 81%|████████▏ | 1302/1600 [10:37<04:56,  1.00it/s] 82%|████████▏ | 1304/1600 [10:37<03:52,  1.27it/s] 82%|████████▏ | 1307/1600 [10:38<02:40,  1.83it/s] 82%|████████▏ | 1310/1600 [10:38<01:52,  2.58it/s] 82%|████████▏ | 1313/1600 [10:38<01:20,  3.56it/s] 82%|████████▏ | 1316/1600 [10:38<00:59,  4.80it/s] 82%|████████▏ | 1319/1600 [10:38<00:44,  6.29it/s]                                                    82%|████████▎ | 1320/1600 [10:38<00:44,  6.29it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.70it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.49it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.05it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.58it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.33it/s][A                                                   
                                               [A 82%|████████▎ | 1320/1600 [10:39<00:44,  6.29it/s]
100%|██████████| 20/20 [00:00<00:00, 27.33it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1320
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1320/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1320/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1300] due to args.save_total_limit
 83%|████████▎ | 1322/1600 [10:47<04:42,  1.02s/it] 83%|████████▎ | 1325/1600 [10:47<03:18,  1.38it/s] 83%|████████▎ | 1328/1600 [10:47<02:20,  1.93it/s] 83%|████████▎ | 1331/1600 [10:47<01:41,  2.66it/s] 83%|████████▎ | 1334/1600 [10:48<01:13,  3.62it/s] 84%|████████▎ | 1337/1600 [10:48<00:54,  4.83it/s] 84%|████████▍ | 1340/1600 [10:48<00:40,  6.41it/s]                                                    84%|████████▍ | 1340/1600 [10:48<00:40,  6.41it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.79it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.59it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.10it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.62it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.39it/s][A                                                   
                                               [A 84%|████████▍ | 1340/1600 [10:49<00:40,  6.41it/s]
100%|██████████| 20/20 [00:00<00:00, 27.39it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1340
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1340/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1340/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1320] due to args.save_total_limit
 84%|████████▍ | 1343/1600 [10:57<04:16,  1.00it/s] 84%|████████▍ | 1346/1600 [10:57<03:01,  1.40it/s] 84%|████████▍ | 1349/1600 [10:57<02:09,  1.94it/s] 84%|████████▍ | 1352/1600 [10:57<01:32,  2.68it/s] 85%|████████▍ | 1355/1600 [10:57<01:07,  3.64it/s] 85%|████████▍ | 1358/1600 [10:57<00:49,  4.87it/s]                                                    85%|████████▌ | 1360/1600 [10:58<00:49,  4.87it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.49it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.32it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.83it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.40it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.16it/s][A                                                   
                                               [A 85%|████████▌ | 1360/1600 [10:58<00:49,  4.87it/s]
100%|██████████| 20/20 [00:00<00:00, 27.16it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1360
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1360/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1360/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1340] due to args.save_total_limit
 85%|████████▌ | 1361/1600 [11:07<04:14,  1.07s/it] 85%|████████▌ | 1364/1600 [11:07<02:59,  1.32it/s] 85%|████████▌ | 1367/1600 [11:07<02:07,  1.83it/s] 86%|████████▌ | 1370/1600 [11:07<01:30,  2.53it/s] 86%|████████▌ | 1373/1600 [11:07<01:05,  3.45it/s] 86%|████████▌ | 1376/1600 [11:07<00:48,  4.62it/s] 86%|████████▌ | 1379/1600 [11:07<00:36,  6.06it/s]                                                    86%|████████▋ | 1380/1600 [11:08<00:36,  6.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.54it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.42it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.93it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.43it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.26it/s][A                                                   
                                               [A 86%|████████▋ | 1380/1600 [11:08<00:36,  6.06it/s]
100%|██████████| 20/20 [00:00<00:00, 27.26it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1380
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1380/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1380/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1360] due to args.save_total_limit
 86%|████████▋ | 1382/1600 [11:16<03:40,  1.01s/it] 87%|████████▋ | 1385/1600 [11:17<02:35,  1.39it/s] 87%|████████▋ | 1388/1600 [11:17<01:49,  1.93it/s] 87%|████████▋ | 1391/1600 [11:17<01:18,  2.65it/s] 87%|████████▋ | 1394/1600 [11:17<00:56,  3.61it/s] 87%|████████▋ | 1397/1600 [11:17<00:41,  4.84it/s] 88%|████████▊ | 1400/1600 [11:17<00:31,  6.41it/s]                                                    88%|████████▊ | 1400/1600 [11:17<00:31,  6.41it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.68it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.54it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.11it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.60it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.34it/s][A                                                   
                                               [A 88%|████████▊ | 1400/1600 [11:18<00:31,  6.41it/s]
100%|██████████| 20/20 [00:00<00:00, 27.34it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1400
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1400/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1400/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1380] due to args.save_total_limit
 88%|████████▊ | 1403/1600 [11:26<03:24,  1.04s/it] 88%|████████▊ | 1406/1600 [11:27<02:23,  1.35it/s] 88%|████████▊ | 1409/1600 [11:27<01:41,  1.89it/s] 88%|████████▊ | 1412/1600 [11:27<01:12,  2.59it/s] 88%|████████▊ | 1415/1600 [11:27<00:52,  3.52it/s] 89%|████████▊ | 1418/1600 [11:27<00:38,  4.73it/s]                                                    89%|████████▉ | 1420/1600 [11:27<00:38,  4.73it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.52it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.41it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.93it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.43it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.14it/s][A                                                   
                                               [A 89%|████████▉ | 1420/1600 [11:28<00:38,  4.73it/s]
100%|██████████| 20/20 [00:00<00:00, 27.14it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1420
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1420/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1420/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1400] due to args.save_total_limit
 89%|████████▉ | 1421/1600 [11:36<03:07,  1.05s/it] 89%|████████▉ | 1423/1600 [11:36<02:26,  1.21it/s] 89%|████████▉ | 1426/1600 [11:36<01:39,  1.74it/s] 89%|████████▉ | 1429/1600 [11:37<01:09,  2.46it/s] 90%|████████▉ | 1432/1600 [11:37<00:49,  3.40it/s] 90%|████████▉ | 1435/1600 [11:37<00:35,  4.58it/s] 90%|████████▉ | 1438/1600 [11:37<00:26,  6.06it/s]                                                    90%|█████████ | 1440/1600 [11:37<00:26,  6.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.53it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.28it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.86it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.42it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.23it/s][A                                                   
                                               [A 90%|█████████ | 1440/1600 [11:38<00:26,  6.06it/s]
100%|██████████| 20/20 [00:00<00:00, 27.23it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1440
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1440/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1440/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1420] due to args.save_total_limit
 90%|█████████ | 1441/1600 [11:46<02:41,  1.02s/it] 90%|█████████ | 1444/1600 [11:46<01:53,  1.38it/s] 90%|█████████ | 1447/1600 [11:46<01:19,  1.92it/s] 91%|█████████ | 1450/1600 [11:46<00:56,  2.66it/s] 91%|█████████ | 1453/1600 [11:46<00:40,  3.61it/s] 91%|█████████ | 1456/1600 [11:47<00:29,  4.83it/s] 91%|█████████ | 1459/1600 [11:47<00:22,  6.33it/s]                                                    91%|█████████▏| 1460/1600 [11:47<00:22,  6.33it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.78it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.61it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.10it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.55it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.32it/s][A                                                   
                                               [A 91%|█████████▏| 1460/1600 [11:48<00:22,  6.33it/s]
100%|██████████| 20/20 [00:00<00:00, 27.32it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1460
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1460/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1460/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1440] due to args.save_total_limit
 91%|█████████▏| 1462/1600 [11:56<02:30,  1.09s/it] 92%|█████████▏| 1464/1600 [11:57<01:56,  1.16it/s] 92%|█████████▏| 1467/1600 [11:57<01:19,  1.68it/s] 92%|█████████▏| 1470/1600 [11:57<00:54,  2.36it/s] 92%|█████████▏| 1473/1600 [11:57<00:38,  3.29it/s] 92%|█████████▏| 1476/1600 [11:57<00:27,  4.44it/s] 92%|█████████▏| 1479/1600 [11:57<00:20,  5.84it/s]                                                    92%|█████████▎| 1480/1600 [11:57<00:20,  5.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.15it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.19it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.72it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.27it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.12it/s][A                                                   
                                               [A 92%|█████████▎| 1480/1600 [11:58<00:20,  5.84it/s]
100%|██████████| 20/20 [00:00<00:00, 27.12it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1480
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1480/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1480/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1460] due to args.save_total_limit
 93%|█████████▎| 1482/1600 [12:07<02:07,  1.08s/it] 93%|█████████▎| 1485/1600 [12:07<01:28,  1.30it/s] 93%|█████████▎| 1488/1600 [12:07<01:01,  1.81it/s] 93%|█████████▎| 1491/1600 [12:07<00:43,  2.51it/s] 93%|█████████▎| 1494/1600 [12:07<00:30,  3.43it/s] 94%|█████████▎| 1497/1600 [12:07<00:22,  4.63it/s] 94%|█████████▍| 1500/1600 [12:08<00:16,  6.15it/s]                                                    94%|█████████▍| 1500/1600 [12:08<00:16,  6.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.66it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.44it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.92it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.43it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.19it/s][A                                                   
                                               [A 94%|█████████▍| 1500/1600 [12:08<00:16,  6.15it/s]
100%|██████████| 20/20 [00:00<00:00, 27.19it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1500/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1500/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1480] due to args.save_total_limit
 94%|█████████▍| 1503/1600 [12:17<01:38,  1.02s/it] 94%|█████████▍| 1506/1600 [12:17<01:08,  1.38it/s] 94%|█████████▍| 1509/1600 [12:17<00:47,  1.92it/s] 94%|█████████▍| 1512/1600 [12:17<00:33,  2.65it/s] 95%|█████████▍| 1515/1600 [12:17<00:23,  3.60it/s] 95%|█████████▍| 1518/1600 [12:17<00:16,  4.83it/s]                                                    95%|█████████▌| 1520/1600 [12:17<00:16,  4.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.69it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.48it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.92it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.38it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.15it/s][A                                                   
                                               [A 95%|█████████▌| 1520/1600 [12:18<00:16,  4.83it/s]
100%|██████████| 20/20 [00:00<00:00, 27.15it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1520
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1520/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1520/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1500] due to args.save_total_limit
 95%|█████████▌| 1521/1600 [12:26<01:22,  1.04s/it] 95%|█████████▌| 1523/1600 [12:26<01:03,  1.21it/s] 95%|█████████▌| 1525/1600 [12:26<00:47,  1.57it/s] 96%|█████████▌| 1528/1600 [12:27<00:31,  2.29it/s] 96%|█████████▌| 1531/1600 [12:27<00:21,  3.25it/s] 96%|█████████▌| 1534/1600 [12:27<00:14,  4.46it/s] 96%|█████████▌| 1537/1600 [12:27<00:10,  5.94it/s] 96%|█████████▋| 1540/1600 [12:27<00:07,  7.80it/s]                                                    96%|█████████▋| 1540/1600 [12:27<00:07,  7.80it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.04it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.26it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.86it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.44it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.20it/s][A                                                   
                                               [A 96%|█████████▋| 1540/1600 [12:28<00:07,  7.80it/s]
100%|██████████| 20/20 [00:00<00:00, 27.20it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1540
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1540/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1540/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1520] due to args.save_total_limit
 96%|█████████▋| 1543/1600 [12:36<00:57,  1.00s/it] 97%|█████████▋| 1545/1600 [12:36<00:43,  1.27it/s] 97%|█████████▋| 1548/1600 [12:36<00:28,  1.83it/s] 97%|█████████▋| 1551/1600 [12:36<00:18,  2.59it/s] 97%|█████████▋| 1554/1600 [12:37<00:12,  3.58it/s] 97%|█████████▋| 1557/1600 [12:37<00:08,  4.83it/s] 98%|█████████▊| 1560/1600 [12:37<00:06,  6.44it/s]                                                    98%|█████████▊| 1560/1600 [12:37<00:06,  6.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.41it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.30it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.86it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.41it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.23it/s][A                                                   
                                               [A 98%|█████████▊| 1560/1600 [12:38<00:06,  6.44it/s]
100%|██████████| 20/20 [00:00<00:00, 27.23it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1560
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1560/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1560/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1540] due to args.save_total_limit
 98%|█████████▊| 1563/1600 [12:46<00:37,  1.01s/it] 98%|█████████▊| 1566/1600 [12:46<00:24,  1.39it/s] 98%|█████████▊| 1569/1600 [12:46<00:16,  1.94it/s] 98%|█████████▊| 1572/1600 [12:46<00:10,  2.67it/s] 98%|█████████▊| 1575/1600 [12:46<00:06,  3.64it/s] 99%|█████████▊| 1578/1600 [12:46<00:04,  4.87it/s]                                                    99%|█████████▉| 1580/1600 [12:47<00:04,  4.87it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.74it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.64it/s][A
 60%|██████    | 12/20 [00:00<00:00, 30.21it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.65it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.34it/s][A                                                   
                                               [A 99%|█████████▉| 1580/1600 [12:47<00:04,  4.87it/s]
100%|██████████| 20/20 [00:00<00:00, 27.34it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1580
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1580/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1580/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1560] due to args.save_total_limit
 99%|█████████▉| 1581/1600 [12:55<00:19,  1.03s/it] 99%|█████████▉| 1584/1600 [12:55<00:11,  1.36it/s] 99%|█████████▉| 1587/1600 [12:56<00:06,  1.89it/s] 99%|█████████▉| 1590/1600 [12:56<00:03,  2.61it/s]100%|█████████▉| 1593/1600 [12:56<00:01,  3.56it/s]100%|█████████▉| 1596/1600 [12:56<00:00,  4.76it/s]100%|█████████▉| 1599/1600 [12:56<00:00,  6.23it/s]                                                   100%|██████████| 1600/1600 [12:56<00:00,  6.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 2490
  Batch size = 128

  0%|          | 0/20 [00:00<?, ?it/s][A
 20%|██        | 4/20 [00:00<00:00, 36.54it/s][A
 40%|████      | 8/20 [00:00<00:00, 30.22it/s][A
 60%|██████    | 12/20 [00:00<00:00, 29.75it/s][A
 80%|████████  | 16/20 [00:00<00:00, 28.38it/s][A
 95%|█████████▌| 19/20 [00:00<00:00, 27.21it/s][A                                                   
                                               [A100%|██████████| 1600/1600 [12:57<00:00,  6.23it/s]
100%|██████████| 20/20 [00:00<00:00, 27.21it/s][A
                                               [ASaving model checkpoint to /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1600
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
tokenizer config file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1600/tokenizer_config.json
Special tokens file saved in /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1600/special_tokens_map.json
Deleting older checkpoint [/home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1580] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from /home/bhanuv/projects/multilingual_agnostic/classification_checkpoints/mbart_agnostic/checkpoint-1600 (score: 1.0474176406860352).
                                                   100%|██████████| 1600/1600 [13:07<00:00,  6.23it/s]100%|██████████| 1600/1600 [13:07<00:00,  2.03it/s]
The following columns in the test set  don't have a corresponding argument in `MBart.forward` and have been ignored: hypothesis, premise. If hypothesis, premise are not expected by `MBart.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 2490
  Batch size = 128
  0%|          | 0/20 [00:00<?, ?it/s] 20%|██        | 4/20 [00:00<00:00, 28.77it/s] 35%|███▌      | 7/20 [00:00<00:00, 24.53it/s] 50%|█████     | 10/20 [00:00<00:00, 23.39it/s] 65%|██████▌   | 13/20 [00:00<00:00, 22.77it/s] 80%|████████  | 16/20 [00:00<00:00, 21.97it/s] 95%|█████████▌| 19/20 [00:00<00:00, 21.17it/s]100%|██████████| 20/20 [00:01<00:00, 18.26it/s]